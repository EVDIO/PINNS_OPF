{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pd.read_csv(r\"C:\\Users\\Dell\\Documents\\GitHub\\pinns_opf\\data\\raw\\lines_33.csv\")\n",
    "nodes = pd.read_csv(r\"C:\\Users\\Dell\\Documents\\GitHub\\pinns_opf\\data\\raw\\nodes_33.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_index = nodes['Nodes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data.npy\"\n",
    "\n",
    "with open(file_path, \"rb\") as file:\n",
    "    data_array = np.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 203)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you already have the 'data_array' with shape (24, num_columns)\n",
    "num_copies = 100\n",
    "\n",
    "# Create an array of shape (num_copies, 1) to repeat 'data_array' vertically\n",
    "repeated_array = np.tile(data_array, (num_copies, 1))\n",
    "\n",
    "# Stack the repeated arrays vertically\n",
    "data_array_extended = np.vstack(repeated_array)\n",
    "\n",
    "print(data_array_extended.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2399, 203), (2399, 203))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data_array_extended[1:]\n",
    "targets = data_array_extended[:-1]\n",
    "features.shape,targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = np.array([lines['From'].values,lines['To'].values])\n",
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resistance =  np.array(lines['R'].values)\n",
    "reactance = np.array(lines['X'].values)\n",
    "static_edge_features = np.stack([resistance, reactance]).transpose()\n",
    "static_edge_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_weights = np.ones((32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StaticGraphTemporalSignal(\n",
    "    edge_index = edge_index, edge_weight = edge_weights ,features = features, targets = targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import A3TGCN2\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "\n",
    "# GPU support\n",
    "DEVICE = torch.device('cpu') # cuda\n",
    "shuffle=True\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GConvGRU(torch.nn.Module):\n",
    "    \n",
    "#------------------------------------------------------------------------init\n",
    "    def __init__( self, in_channels: int, out_channels: int, K: int,normalization: str = \"sym\",bias: bool = True ):\n",
    "        super(GConvGRU, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "        self.conv_x_z = ChebConv(in_channels=self.in_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "        self.conv_h_z = ChebConv(in_channels=self.out_channels,out_channels=self.out_channels, K=self.K, normalization=self.normalization, bias=self.bias)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "        self.conv_x_r = ChebConv( in_channels=self.in_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n",
    "        self.conv_h_r = ChebConv( in_channels=self.out_channels,out_channels=self.out_channels, K=self.K,  normalization=self.normalization, bias=self.bias )\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "        self.conv_x_h = ChebConv(  in_channels=self.in_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n",
    "        self.conv_h_h = ChebConv(  in_channels=self.out_channels, out_channels=self.out_channels, K=self.K,normalization=self.normalization,bias=self.bias)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "        \n",
    "#-------------------------------------------------------------------------------------------\n",
    "    def _set_hidden_state(self, X): # step 1\n",
    "        H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "#---------------------------------------------------\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H): # step 2\n",
    "        Z = self.conv_x_z(X, edge_index, edge_weight)\n",
    "        Z = Z + self.conv_h_z(H, edge_index, edge_weight)\n",
    "        Z = torch.sigmoid(Z)\n",
    "        return Z\n",
    "#------------------------------------------------------\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H):\n",
    "        R = self.conv_x_r(X, edge_index, edge_weight)\n",
    "        R = R + self.conv_h_r(H, edge_index, edge_weight)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "#------------------------- # Step 4\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R):\n",
    "        H_tilde = self.conv_x_h(X, edge_index, edge_weight)\n",
    "        H_tilde = H_tilde + self.conv_h_h(H * R, edge_index, edge_weight)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "#-------------------------------\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde):\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward( self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None) -> torch.FloatTensor:\n",
    "        H = self._set_hidden_state(X) # step 1 # X (20,4) H (20,32)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H) # step 2 Z (20, 32)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H) # step 3  R (20, 32)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R) # step 4 H_tilde (20, 32)\n",
    "        \n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde) # step 5  H (20, 32)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DConv(MessagePassing):\n",
    "    \n",
    "#----------------------------------------- init\n",
    "    def __init__(self, in_channels, out_channels, K, bias=True):\n",
    "        super(DConv, self).__init__(aggr=\"add\", flow=\"source_to_target\")\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(2, K, in_channels, out_channels))  # 2, 32, 20,1 ?\n",
    "\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "        self.__reset_parameters()\n",
    "\n",
    "    def __reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.weight)\n",
    "        torch.nn.init.zeros_(self.bias)\n",
    "\n",
    "#---------------------------------------------------\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def forward(self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        \n",
    "        adj_mat = to_dense_adj(edge_index, edge_attr=edge_weight) # create  adjacency matrix shape (1,20,20)\n",
    "        adj_mat = adj_mat.reshape(adj_mat.size(1), adj_mat.size(2)) # (20, 20)\n",
    "        deg_out = torch.matmul(\n",
    "            adj_mat, torch.ones(size=(adj_mat.size(0), 1)).to(X.device)\n",
    "        ) #  (20, 1)\n",
    "        deg_out = deg_out.flatten() # (20)\n",
    "        deg_in = torch.matmul(\n",
    "            torch.ones(size=(1, adj_mat.size(0))).to(X.device), adj_mat\n",
    "        ) # (1, 20)\n",
    "        deg_in = deg_in.flatten() # 20 \n",
    "\n",
    "        deg_out_inv = torch.reciprocal(deg_out) # receprocal of each item 2 will be 1/2 (20)\n",
    "        deg_in_inv = torch.reciprocal(deg_in) # (20)\n",
    "        row, col = edge_index\n",
    "        \n",
    "        norm_out = deg_out_inv[row] # (102)\n",
    "        norm_in = deg_in_inv[row] # (102)\n",
    "\n",
    "        reverse_edge_index = adj_mat.transpose(0, 1) # (20,20)\n",
    "        reverse_edge_index, vv = dense_to_sparse(reverse_edge_index) #  creates sparse adjacency matrix defined by edge indices and edge attributes. # (2, 102), (102)\n",
    "\n",
    "        Tx_0 = X  # (20, 36)\n",
    "        Tx_1 = X  # (20, 36)\n",
    "        # weight is (2, 2, 36, 32) so weight[0][0] is (36, 32) \n",
    "        H = torch.matmul(Tx_0, (self.weight[0])[0]) +  torch.matmul(Tx_0, (self.weight[1])[0]) # (20, 32) # calculate the embedding of each node -> step1\n",
    "\n",
    "        # Step 2 message passing\n",
    "        if self.weight.size(1) > 1:\n",
    "            Tx_1_o = self.propagate(edge_index, x=X, norm=norm_out, size=None) # (20, 36)\n",
    "            Tx_1_i = self.propagate(reverse_edge_index, x=X, norm=norm_in, size=None) # (20, 36)\n",
    "            H = ( H  + torch.matmul(Tx_1_o, (self.weight[0])[1]) + torch.matmul(Tx_1_i, (self.weight[1])[1]) ) #(20, 32)\n",
    "            \n",
    "        #for k in range(2, self.weight.size(1)): # not true\n",
    "        #    Tx_2_o = self.propagate(edge_index, x=Tx_1_o, norm=norm_out, size=None)\n",
    "        #    Tx_2_o = 2.0 * Tx_2_o - Tx_0  # (20, 36)\n",
    "        #    Tx_2_i = self.propagate(reverse_edge_index, x=Tx_1_i, norm=norm_in, size=None)\n",
    "        #    Tx_2_i = 2.0 * Tx_2_i - Tx_0\n",
    "        #    H = (H + torch.matmul(Tx_2_o, (self.weight[0])[k]) + torch.matmul(Tx_2_i, (self.weight[1])[k]))\n",
    "        #    Tx_0, Tx_1_o, Tx_1_i = Tx_1, Tx_2_o, Tx_2_i\n",
    "\n",
    "        if self.bias is not None:\n",
    "            H += self.bias\n",
    "\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCRNN(torch.nn.Module):\n",
    "    #----------------------------------------------------init\n",
    "    def __init__(self, in_channels: int, out_channels: int, K: int, bias: bool = True):\n",
    "        super(DCRNN, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "\n",
    "    def _create_update_gate_parameters_and_layers(self):\n",
    "        self.conv_x_z = DConv(in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, K=self.K, bias=self.bias)\n",
    "\n",
    "    def _create_reset_gate_parameters_and_layers(self):\n",
    "        self.conv_x_r = DConv( in_channels=self.in_channels + self.out_channels,out_channels=self.out_channels, K=self.K, bias=self.bias)\n",
    "\n",
    "    def _create_candidate_state_parameters_and_layers(self):\n",
    "        self.conv_x_h = DConv( in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, K=self.K, bias=self.bias)\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_update_gate_parameters_and_layers()\n",
    "        self._create_reset_gate_parameters_and_layers()\n",
    "        self._create_candidate_state_parameters_and_layers()\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "    def _set_hidden_state(self, X, H): # step 1\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _calculate_update_gate(self, X, edge_index, edge_weight, H): # step 2\n",
    "        Z = torch.cat([X, H], dim=1) # (20, 36)\n",
    "        Z = self.conv_x_z(Z, edge_index, edge_weight) # (20, 32)\n",
    "        Z = torch.sigmoid(Z)\n",
    "\n",
    "        return Z\n",
    "\n",
    "    def _calculate_reset_gate(self, X, edge_index, edge_weight, H): # step 3\n",
    "        R = torch.cat([X, H], dim=1)\n",
    "        R = self.conv_x_r(R, edge_index, edge_weight)\n",
    "        R = torch.sigmoid(R)\n",
    "        return R\n",
    "\n",
    "    def _calculate_candidate_state(self, X, edge_index, edge_weight, H, R): # step 4\n",
    "        H_tilde = torch.cat([X, H * R], dim=1)\n",
    "        H_tilde = self.conv_x_h(H_tilde, edge_index, edge_weight)\n",
    "        H_tilde = torch.tanh(H_tilde)\n",
    "        return H_tilde\n",
    "\n",
    "    def _calculate_hidden_state(self, Z, H, H_tilde): # step 5\n",
    "        H = Z * H + (1 - Z) * H_tilde\n",
    "        return H\n",
    "\n",
    "    def forward( self, X: torch.FloatTensor, edge_index: torch.LongTensor, edge_weight: torch.FloatTensor = None, H: torch.FloatTensor = None) -> torch.FloatTensor:\n",
    "        H = self._set_hidden_state(X, H)  # X(20,4) H(20, 32)\n",
    "        Z = self._calculate_update_gate(X, edge_index, edge_weight, H) # Z (20,32)\n",
    "        R = self._calculate_reset_gate(X, edge_index, edge_weight, H) # R (20,32)\n",
    "        H_tilde = self._calculate_candidate_state(X, edge_index, edge_weight, H, R) # H_tilde (20, 32)\n",
    "        H = self._calculate_hidden_state(Z, H, H_tilde) # H (20, 32)\n",
    "        return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, filters):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, filters, 2) # or use  GConvGRU(node_features, filters, 2) both will lead to similar results\n",
    "        self.linear = torch.nn.Linear(filters, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight) # h (20, 32)\n",
    "        h = F.relu(h) # h (20, 32)\n",
    "\n",
    "        h = self.linear(h) # h (20, 1)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features=4, filters=32)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StaticGraphTemporalSignal' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m loader \u001b[39m=\u001b[39m ChickenpoxDatasetLoader()\n\u001b[0;32m      3\u001b[0m dataset \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget_dataset()\n\u001b[1;32m----> 4\u001b[0m dataset\u001b[39m.\u001b[39;49mx\u001b[39m.\u001b[39mshape, dataset\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mshape , dataset\u001b[39m.\u001b[39medge_attr\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StaticGraphTemporalSignal' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "loader = ChickenpoxDatasetLoader()\n",
    "dataset = loader.get_dataset()\n",
    "dataset.x.shape, dataset.edge_index.shape , dataset.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 4]), torch.Size([2, 102]), torch.Size([102]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot.x.shape, snapshot.edge_index.shape , snapshot.edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0--cost is 1.356619\n",
      "epoch 1--cost is 1.331168\n",
      "epoch 2--cost is 1.342036\n",
      "epoch 3--cost is 1.312562\n",
      "epoch 4--cost is 1.313701\n",
      "epoch 5--cost is 1.306513\n",
      "epoch 6--cost is 1.306989\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    print(\"epoch {}--cost is {}\".format(epoch, round(cost.item(),6)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opf_pinns_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
